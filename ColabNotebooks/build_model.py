# -*- coding: utf-8 -*-
"""build_model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10Q1qjc0aAU0gBaYGezQDwBSQjMO6fmP7
"""

!pip install keras-tuner

import tensorflow as tf
from tensorflow import keras 
import numpy as np
import shutil

basepath = '/content/drive/My Drive/Colab Notebooks/Pneumonia_classifier'

import os,pickle

pickle_in = open(os.path.join(basepath,'train_test_dataset', 'train_X'),'rb')
train_X = pickle.load(pickle_in)
pickle_in.close()    


pickle_in = open(os.path.join(basepath,'train_test_dataset', 'test_X'),'rb')
test_X = pickle.load(pickle_in)
pickle_in.close()    


pickle_in = open(os.path.join(basepath,'train_test_dataset','train_y'),'rb')
train_y = pickle.load(pickle_in)
pickle_in.close()    


pickle_in = open(os.path.join(basepath,'train_test_dataset', 'test_y'),'rb')
test_y = pickle.load(pickle_in)
pickle_in.close()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input, SeparableConv2D, BatchNormalization, MaxPool2D, Dropout ,Flatten

def create_model(hp):
  
  def add_sep_conv_block(model, num_filters, kernel_size, normalization = 1,dropout_rate=0):
    model.add(SeparableConv2D(filters = num_filters , kernel_size = kernel_size, padding = 'same', activation = 'relu'))
    model.add(SeparableConv2D(filters = num_filters , kernel_size = kernel_size, padding = 'same', activation = 'relu'))
    if normalization :
      model.add(BatchNormalization())
    model.add(MaxPool2D(pool_size=(2,2)))
    model.add(Dropout(rate = dropout_rate))
    return model

  def add_fc_layer(model,dense_units,dropout_rate=0):
    model.add(Dense(units = dense_units, activation = 'relu'))
    model.add(Dropout(rate = dropout_rate))
    return model


  model = tf.keras.models.Sequential()
  #INPUT SHAPE
  model.add(Input(shape=(120, 100, 1)))
  #FIRST CONV BLOCK
  add_sep_conv_block(model,num_filters = hp.Int('conv_1_filter',min_value =16, max_value=104,step = 8),kernel_size = hp.Choice('conv_1_kernel',values = [3,5]),normalization = 0)
  #SECOND CONV BLOCK
  add_sep_conv_block(model,num_filters = hp.Int('conv_2_filter',min_value =16, max_value=104,step = 8),kernel_size = hp.Choice('conv_2_kernel',values = [3,5]))
  
  #THIRD CONV BLOCK
  add_sep_conv_block(model,num_filters = hp.Int('conv_3_filter',min_value =16, max_value=104,step = 8),kernel_size = hp.Choice('conv_3_kernel',values = [3,5]))
  
  #FLATTEN
  model.add(Flatten())
  #FC LAYER
  add_fc_layer(model,dense_units = hp.Int('dense_1_units',min_value =32, max_value=128,step = 8), dropout_rate = 0.5)
  #add_fc_layer(model,128,0.4)
  add_fc_layer(model,dense_units = hp.Int('dense_2_units',min_value =32, max_value=128,step = 8),dropout_rate = 0.3)
  #OUTPUT LAYER
  model.add(Dense(units = 1, activation = 'sigmoid'))

  model.compile(optimizer= 'Adam', loss= 'binary_crossentropy', metrics= ['accuracy'])

  return model

from kerastuner import RandomSearch
from kerastuner.engine.hyperparameters import HyperParameters

tuner_search = RandomSearch(create_model,
                            objective='val_accuracy',
                            max_trials=5,directory=basepath,
                            project_name='Tuner_Folder')

tuner_search.search(train_X,train_y,epochs=3,validation_split=0.2)

model = tuner_search.get_best_models(num_models=1)[0]

model.summary()

model_history = model.fit(train_X,train_y,epochs=10, validation_split=0.1,initial_epoch=3,callbacks= [
        tf.keras.callbacks.ModelCheckpoint('models/model_{val_accuracy:.3f}.h5',
        save_best_only = True,save_weights_only = False,
        monitor = 'val_accuracy')
    ])

model.save('model_final.h5')

import matplotlib.pyplot as plt

accs = model_history.history['accuracy']
val_accs = model_history.history['val_accuracy']

loss = model_history.history['loss']
val_loss = model_history.history['val_loss']

fig, (ax1, ax2) = plt.subplots(1,2,figsize=(20,7))

ax1.plot(range(len(accs)),accs,'b',label='Training')
ax1.plot(range(len(val_accs)),val_accs,'--r',label='Validation')
l1 = ax1.legend()
ax1.title.set_text('Accuracy: Training vs Validation')


ax2.plot(range(len(loss)),loss,'b',label='Training')
ax2.plot(range(len(val_loss)),val_loss,'--r',label='Validation')
l2 = ax2.legend()
ax2.title.set_text('Loss: Training vs Validation')

fig.savefig(os.path.join(basepath,'Accuracy and Loss Plots'))

preds = model.predict(test_X)
preds = (preds >= 0.5)*1

from sklearn.metrics import accuracy_score, classification_report , confusion_matrix
def Evaluate(test_y,preds):
  cm = confusion_matrix(test_y,preds)
  acc = accuracy_score(test_y, preds)*100
  cr = classification_report(test_y,preds)
  print("Confusion_matrix : ")
  print()
  print(cm)
  print()
  print("Accuracy : ",acc,"%")
  print()
  print("Classification Report : ")
  print()
  print(cr)

Evaluate(test_y,preds)

shutil.move('model_final.h5',basepath)